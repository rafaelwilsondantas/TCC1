%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% CAPÍTULO 2
\chapter{FUNDAMENTAÇÃO TEÓRICA}  


\section{Teorema de Bayes} \label{teoremaBayes}

\section{Classificadores Bayesianos}
Os classificadores Bayesianos surgiram com base no Teorma de Bayses, que foi apresentado na seção \ref{teoremaBayes}. 
Segundo XXXXX, por ser um classificador probabilístico simples, asssumindo que todas as características são indepentes entre si, o classificador Naive Bayes é bastante utilizado e conhecido na mineração de dados.
O algoritmo do classificador Naive Bayes funciona da seguinte forma:
Dado um conjunto de treinamento \simbolo{$Tr$}{comprimento de onda}



\section{K-Dependence Bayesian Classifier (KDBC)} \label{kdbc}

\section{Problema}

Como visto na seção \ref{kdbc} o possível número de modelos gerados pelo KDBC para a representação do classificador é determinado pela equação X. A equação cresce exponencialmente em função do número de atributos e do número de k-dependencias. 
Assim, com o crescimento do número de atributos ou da exigência de um número maior de k-dependencias, gerar todos os modelos ou escolher o melhor modelo para o problema torna-se computacionalmente muito custoso.


