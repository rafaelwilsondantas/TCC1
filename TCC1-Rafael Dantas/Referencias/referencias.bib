% This file was created with JabRef 2.3.1.
% Encoding: Cp1252

@MISC{BlUM2005,
    author = {Christian Blum},
    title = { Ant colony optimization: Introduction and recent trends},
    year = {2005}
}

@article{LARRANAGA2013,
title = "A review on evolutionary algorithms in Bayesian network learning and inference tasks ",
journal = "Information Sciences ",
volume = "233",
number = "",
pages = "109 - 125",
year = "2013",
note = "",
issn = "0020-0255",
doi = "https://doi.org/10.1016/j.ins.2012.12.051",
url = "http://www.sciencedirect.com/science/article/pii/S0020025513000443",
author = "Pedro Larrannaga and Hossein Karshenas and Concha Bielza and Roberto Santana",
keywords = "Probabilistic graphical model",
keywords = "Bayesian network",
keywords = "Evolutionary computation",
keywords = "Inference",
keywords = "Learning from data "
}
@article{COOPER1990,
 author = {Cooper, Gregory F.},
 title = {The Computational Complexity of Probabilistic Inference Using Bayesian Belief Networks (Research Note)},
 journal = {Artif. Intell.},
 issue_date = {March 1990},
 volume = {42},
 number = {2-3},
 month = mar,
 year = {1990},
 issn = {0004-3702},
 pages = {393--405},
 numpages = {13},
 url = {http://dx.doi.org/10.1016/0004-3702(90)90060-D},
 doi = {10.1016/0004-3702(90)90060-D},
 acmid = {77762},
 publisher = {Elsevier Science Publishers Ltd.},
 address = {Essex, UK},
} 
@article{DORIGO2005,
title = "Ant colony optimization theory: A survey",
journal = "Theoretical Computer Science",
volume = "344",
number = "2",
pages = "243 - 278",
year = "2005",
note = "",
issn = "0304-3975",
doi = "http://dx.doi.org/10.1016/j.tcs.2005.05.020",
url = "http://www.sciencedirect.com/science/article/pii/S0304397505003798",
author = "Marco Dorigo and Christian Blum",
keywords = "Ant colony optimization",
keywords = "Metaheuristics",
keywords = "Combinatorial optimization",
keywords = "Convergence",
keywords = "Stochastic gradient descent",
keywords = "Model-based search",
keywords = "Approximate algorithms"
}
@book{CAMPELLO1994,
  title={Algoritmos e heuristicas: desenvolvimento e avaliacao de performance},
  author={Campello, R.E. and MACULAN, N.},
  isbn={9788522801343},
  url={https://books.google.com.br/books?id=oUOBPgAACAAJ},
  year={1994},
  publisher={EDUFF}
}
@ARTICLE{DORIGO1996,
author={M. Dorigo and V. Maniezzo and A. Colorni},
journal={IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
title={Ant system: optimization by a colony of cooperating agents},
year={1996},
volume={26},
number={1},
pages={29-41},
keywords={feedback;optimisation;robust control;search problems;simulated annealing;stochastic programming;travelling salesman problems;ant colonies;ant system;computational paradigm;constructive greedy heuristic;cooperating agents;distributed communication;distributed computation;global data structure revision;job-shop scheduling;optimization;parameter selection;positive feedback;probabilistic transitions;quadratic assignment;simulated annealing;stochastic combinatorial optimization;tabu search;traveling salesman problem;Ant colony optimization;Artificial intelligence;Computational modeling;Data structures;Distributed computing;Feedback;Intelligent robots;Robustness;Simulated annealing;Traveling salesman problems},
doi={10.1109/3477.484436},
ISSN={1083-4419},
month={Feb}
}
@book{DOUGHERTY2012,
 author = {Dougherty, Geoff},
 title = {Pattern Recognition and Classification: An Introduction},
 year = {2012},
 isbn = {1461453224, 9781461453222},
 publisher = {Springer Publishing Company, Incorporated},
} 

@Inbook{DREO2002,
author="Dr{\'e}o, Johann
and Siarry, Patrick",
editor="Dorigo, Marco
and Di Caro, Gianni
and Sampels, Michael",
title="A New Ant Colony Algorithm Using the Heterarchical Concept Aimed at Optimization of Multiminima Continuous Functions",
bookTitle="Ant Algorithms: Third International Workshop, ANTS 2002 Brussels, Belgium, September 12--14, 2002 Proceedings",
year="2002",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="216--221",
isbn="978-3-540-45724-4",
doi="10.1007/3-540-45724-0_18",
url="http://dx.doi.org/10.1007/3-540-45724-0_18"
}

@Article{FLORES2011,
author="Flores, M. Julia
and G{\'a}mez, Jos{\'e} A.
and Mart{\'i}nez, Ana M.
and Puerta, Jos{\'e} M.",
title="Handling numeric attributes when comparing Bayesian network classifiers: does the discretization method matter?",
journal="Applied Intelligence",
year="2011",
volume="34",
number="3",
pages="372--385",
abstract="Within the framework of Bayesian networks (BNs), most classifiers assume that the variables involved are of a discrete nature, but this assumption rarely holds in real problems. Despite the loss of information discretization entails, it is a direct easy-to-use mechanism that can offer some benefits: sometimes discretization improves the run time for certain algorithms; it provides a reduction in the value set and then a reduction in the noise which might be present in the data; in other cases, there are some Bayesian methods that can only deal with discrete variables. Hence, even though there are many ways to deal with continuous variables other than discretization, it is still commonly used. This paper presents a study of the impact of using different discretization strategies on a set of representative BN classifiers, with a significant sample consisting of 26 datasets. For this comparison, we have chosen Naive Bayes (NB) together with several other semi-Naive Bayes classifiers: Tree-Augmented Naive Bayes (TAN), k-Dependence Bayesian (KDB), Aggregating One-Dependence Estimators (AODE) and Hybrid AODE (HAODE). Also, we have included an augmented Bayesian network created by using a hill climbing algorithm (BNHC). With this comparison we analyse to what extent the type of discretization method affects classifier performance in terms of accuracy and bias-variance discretization. Our main conclusion is that even if a discretization method produces different results for a particular dataset, it does not really have an effect when classifiers are being compared. That is, given a set of datasets, accuracy values might vary but the classifier ranking is generally maintained. This is a very useful outcome, assuming that the type of discretization applied is not decisive future experiments can be d times faster, d being the number of discretization methods considered.",
issn="1573-7497",
doi="10.1007/s10489-011-0286-z",
url="http://dx.doi.org/10.1007/s10489-011-0286-z"
}

@article{PENA2004,
 author = {Pena, J. M. and Lozano, J. A. and Larranaga, P.},
 title = {Unsupervised Learning of Bayesian Networks via Estimation of Distribution Algorithms: An Application to Gene Expression Data Clustering},
 journal = {Int. J. Uncertain. Fuzziness Knowl.-Based Syst.},
 issue_date = {January 2004},
 volume = {12},
 number = {1 supp},
 month = jan,
 year = {2004},
 issn = {0218-4885},
 pages = {63--82},
 numpages = {20},
 url = {http://dx.doi.org/10.1142/S0218488504002588},
 doi = {10.1142/S0218488504002588},
 acmid = {991116},
 publisher = {World Scientific Publishing Co., Inc.},
 address = {River Edge, NJ, USA},
 keywords = {Bayesian networks, estimation of distribution algorithms, gene expression data analysis, unsupervised learning},
} 
@article{SIEERA1998,
    address = {Department of Computer Science and Artificial Intelligence, University of the Basque Country, San Sebastian, Spain. ccpsiarb@si.ehu.es},
    author = {Sierra, B. and Larra\~{n}aga, P.},
    issn = {0933-3657},
    journal = {Artif Intell Med},
    keywords = {bayesian\_networks},
    number = {1-2},
    pages = {215--230},
    pmid = {9779891},
    posted-at = {2011-12-25 20:33:13},
    priority = {2},
    title = {{Predicting survival in malignant skin melanoma using Bayesian networks automatically induced by genetic algorithms. An empirical comparison between different approaches.}},
    volume = {14},
    year = {1998}
}


@Article{FRIEDMAN1997,
author="Friedman, Nir
and Geiger, Dan
and Goldszmidt, Moises",
title="Bayesian Network Classifiers",
journal="Machine Learning",
year="1997",
volume="29",
number="2",
pages="131--163",
abstract="Recent work in supervised learning has shown that a surprisingly simple Bayesian classifier with strong assumptions of independence among features, called naive Bayes, is competitive with state-of-the-art classifiers such as C4.5. This fact raises the question of whether a classifier with less restrictive assumptions can perform even better. In this paper we evaluate approaches for inducing classifiers from data, based on the theory of learning Bayesian networks. These networks are factored representations of probability distributions that generalize the naive Bayesian classifier and explicitly represent statements about independence. Among these approaches we single out a method we call Tree Augmented Naive Bayes (TAN), which outperforms naive Bayes, yet at the same time maintains the computational simplicity (no search involved) and robustness that characterize naive Bayes. We experimentally tested these approaches, using problems from the University of California at Irvine repository, and compared them to C4.5, naive Bayes, and wrapper methods for feature selection.",
issn="1573-0565",
doi="10.1023/A:1007465528199",
url="http://dx.doi.org/10.1023/A:1007465528199"
}
@Inbook{JIANG2007,
author="Jiang, Liangxiao
and Wang, Dianhong
and Cai, Zhihua
and Yan, Xuesong",
editor="Alhajj, Reda
and Gao, Hong
and Li, Jianzhong
and Li, Xue
and Za{\"i}ane, Osmar R.",
title="Survey of Improving Naive Bayes for Classification",
bookTitle="Advanced Data Mining and Applications: Third International Conference, ADMA 2007 Harbin, China, August 6-8, 2007. Proceedings",
year="2007",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="134--145",
isbn="978-3-540-73871-8",
doi="10.1007/978-3-540-73871-8_14",
url="http://dx.doi.org/10.1007/978-3-540-73871-8_14"
}
@BOOK{LINDEN2008,
  title = {Algoritmos Gen\'eticos},
  subtitle = {Uma importante ferramenta de intelig\^encia Computacional},
  publisher = {Brasport},
  year = {2008},
  author = {Linden, Ricardo},
  address = {S\~ao Paulo}
}
@inproceedings{SAHAMI1996,
 author = {Sahami, Mehran},
 title = {Learning Limited Dependence Bayesian Classifiers},
 booktitle = {Proceedings of the Second International Conference on Knowledge Discovery and Data Mining},
 series = {KDD'96},
 year = {1996},
 location = {Portland, Oregon},
 pages = {335--338},
 numpages = {4},
 url = {http://dl.acm.org/citation.cfm?id=3001460.3001537},
 acmid = {3001537},
 publisher = {AAAI Press},
} 
@Inbook{SEBASTIANI2010,
author="Sebastiani, Paola
and Abad, Maria M.
and Ramoni, Marco F.",
editor="Maimon, Oded
and Rokach, Lior",
title="Bayesian Networks",
bookTitle="Data Mining and Knowledge Discovery Handbook",
year="2010",
publisher="Springer US",
address="Boston, MA",
pages="175--208",
isbn="978-0-387-09823-4",
doi="10.1007/978-0-387-09823-4_10",
url="http://dx.doi.org/10.1007/978-0-387-09823-4_10"
}
@Inbook{VANLAARHOVEN1987,
author="van Laarhoven, Peter J. M.
and Aarts, Emile H. L.",
title="Simulated annealing",
bookTitle="Simulated Annealing: Theory and Applications",
year="1987",
publisher="Springer Netherlands",
address="Dordrecht",
pages="7--15",
isbn="978-94-015-7744-1",
doi="10.1007/978-94-015-7744-1_2",
url="http://dx.doi.org/10.1007/978-94-015-7744-1_2"
}
@BOOK{WITTEN2017,
 author = {Witten, Ian H. and Frank, Eibe and Hall, Mark A.},
 title = {Data Mining: Practical Machine Learning Tools and Techniques},
 year = {2017},
 isbn = {0123748569, 9780123748560},
 edition = {4rd},
 publisher = {Morgan Kaufmann Publishers Inc.},
 address = {San Francisco, CA, USA},
}

@article{FEO1995,
author="Feo, Thomas A.
and Resende, Mauricio G. C.",
title="Greedy Randomized Adaptive Search Procedures",
journal="Journal of Global Optimization",
year="1995",
volume="6",
number="2",
pages="109--133",
issn="1573-2916"
}
@article{MLADENOVIC1997,
 author = {Mladenovi\'{c}, N. and Hansen, P.},
 title = {Variable Neighborhood Search},
 journal = {Comput. Oper. Res.},
 issue_date = {Nov. 1997},
 volume = {24},
 number = {11},
 month = nov,
 year = {1997},
 issn = {0305-0548},
 pages = {1097--1100},
 numpages = {4},
 acmid = {276985},
 publisher = {Elsevier Science Ltd.},
 address = {Oxford, UK, UK}
} 

@article{STELIOS1981,
author = {Stelios H. Zanakis and James R. Evans},
title = {Heuristic “Optimization”: Why, When, and How to Use It},
journal = {Interfaces},
volume = {11},
number = {5},
pages = {84-91},
year = {1981}
}
@ARTICLE{HIRSCH2007,
author="Hirsch, M. J. and Meneses, C. N. and Pardalos, P. M. and Resende, M. G. C.",
title="Global optimization by continuous grasp",
journal="Optimization Letters",
year="2007",
volume="1",
number="2",
pages="201--212",
abstract="We introduce a novel global optimization method called Continuous GRASP (C-GRASP) which extends Feo and Resende's greedy randomized adaptive search procedure (GRASP) from the domain of discrete optimization to that of continuous global optimization. This stochastic local search method is simple to implement, is widely applicable, and does not make use of derivative information, thus making it a well-suited approach for solving global optimization problems. We illustrate the effectiveness of the procedure on a set of standard test problems as well as two hard global optimization problems.",
issn="1862-4480"
}
